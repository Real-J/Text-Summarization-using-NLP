{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install transformers sentencepiece nltk accelerate protobuf\n",
    "!pip install ipywidgets notebook jupyterlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import heapq\n",
    "import torch\n",
    "import gc\n",
    "from transformers import pipeline\n",
    "\n",
    "def extractive_summarization(text, num_sentences=3):\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    word_frequencies = {}\n",
    "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    \n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            if word not in word_frequencies:\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "    max_freq = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] /= max_freq\n",
    "    \n",
    "    sentence_scores = {}\n",
    "    for sent in sentences:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies:\n",
    "                if sent not in sentence_scores:\n",
    "                    sentence_scores[sent] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word]\n",
    "    \n",
    "    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
    "    return ' '.join(summary_sentences)\n",
    "\n",
    "def abstractive_summarization(text, model_name=\"sshleifer/distilbart-cnn-12-6\"):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    summarizer = pipeline(\"summarization\", model=model_name, tokenizer=model_name, device=0 if torch.cuda.is_available() else -1, use_fast=True)\n",
    "    summary = summarizer(text, max_length=65, min_length=20, do_sample=False)\n",
    "    \n",
    "    del summarizer  # Free memory\n",
    "    gc.collect()\n",
    "    \n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Verify GPU availability\n",
    "print(\"Is CUDA available?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Example usage in Jupyter Notebook:\n",
    "text = \"\"\"Autonomous vehicles are transforming transportation by reducing human intervention in driving. These vehicles use sensors, cameras, LiDAR, and AI algorithms to navigate. The goal is to enhance road safety and reduce traffic congestion. However, challenges such as unpredictable human behavior, adverse weather conditions, and ethical considerations in decision-making remain. Despite these hurdles, continuous advancements in AI and machine learning are making self-driving technology more reliable and accessible.\"\"\"\n",
    "\n",
    "print(\"Extractive Summary:\")\n",
    "print(extractive_summarization(text))\n",
    "\n",
    "print(\"\\nAbstractive Summary:\")\n",
    "print(abstractive_summarization(text))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
